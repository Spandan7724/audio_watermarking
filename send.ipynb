{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from encodec import EncodecModel  # Install with: pip install encodec   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device setup (Check for GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Directory where clean audio files are stored\n",
    "DATASET_DIR = \"data/100_all/preprocessed_audio\"\n",
    "TARGET_SAMPLE_RATE = 24000  # Encodec model operates at 24kHz\n",
    "BATCH_SIZE = 64  # Adjust based on GPU memory\n",
    "NUM_EPOCHS = 5\n",
    "LR = 1e-4  # Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 360573 audio files loaded.\n"
     ]
    }
   ],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, dataset_dir, sample_rate=TARGET_SAMPLE_RATE):\n",
    "        self.files = [os.path.join(dataset_dir, f) for f in os.listdir(dataset_dir) if f.endswith(\".wav\")]\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "        # Resample if necessary\n",
    "        if sr != self.sample_rate:\n",
    "            transform = T.Resample(orig_freq=sr, new_freq=self.sample_rate)\n",
    "            waveform = transform(waveform)\n",
    "\n",
    "        return waveform  # Keep in CPU RAM\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "dataset = AudioDataset(DATASET_DIR)\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} audio files loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spandan/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "encodec_model = EncodecModel.encodec_model_24khz().to(device)\n",
    "encoder = encodec_model.encoder  # Extract encoder part\n",
    "encoder.requires_grad_(True)  # Enable fine-tuning\n",
    "\n",
    "# Define Custom Decoder\n",
    "class CustomDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomDecoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(75, 512)  # Adjust based on encoder output size\n",
    "        self.fc2 = nn.Linear(512, 1024)\n",
    "        self.fc3 = nn.Linear(1024, TARGET_SAMPLE_RATE)  # Output back to waveform\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))  # Tanh keeps output within [-1,1]\n",
    "        return x\n",
    "\n",
    "decoder = CustomDecoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21635/1720832921.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(torch.cuda.is_available()))\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss().to(device)  # Mean Squared Error loss\n",
    "optimizer = optim.AdamW(\n",
    "    list(encoder.parameters()) + list(decoder.parameters()),  \n",
    "    lr=LR,  \n",
    "    betas=(0.9, 0.999),  \n",
    "    weight_decay=1e-5  \n",
    ")\n",
    "\n",
    "# Automatic Mixed Precision (AMP) for GPU training\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/5634 [00:00<?, ?it/s]/tmp/ipykernel_21635/1273916368.py:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/spandan/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([64, 1, 24000])) that is different to the input size (torch.Size([64, 128, 24000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 1/5:   6%|â–‹         | 356/5634 [02:07<31:30,  2.79it/s, loss=0.00609]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m     24\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m---> 26\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Update progress bar with loss\u001b[39;00m\n\u001b[1;32m     29\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\", leave=True)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():  \n",
    "            latent = encoder(batch)  \n",
    "            reconstructed = decoder(latent)  \n",
    "            loss = loss_fn(reconstructed, batch)\n",
    "\n",
    "        # Backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Update progress bar with loss\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Free memory\n",
    "        del batch, latent, reconstructed, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] - Average Loss: {epoch_loss / len(data_loader):.6f}\")\n",
    "\n",
    "print(\"Training Complete! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
