{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "CHUNK #1: Environment and hyperparameters set.\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "AUDIO_LEN   = 16000  # 1 second\n",
    "BATCH_SIZE  = 64\n",
    "LR          = 1e-3\n",
    "HIDDEN_DIM  = 32   # LSTM hidden dimension\n",
    "NUM_BITS    = 16   # message bits\n",
    "CHANNELS    = 32   # initial conv channels\n",
    "OUTPUT_CH   = 128  # final conv channels for the generator\n",
    "STRIDES     = [2, 4, 5, 8]  # downsampling strides\n",
    "LSTM_LAYERS = 2\n",
    "NUM_WORKERS = 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "print(\"\\nCHUNK #1: Environment and hyperparameters set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHUNK #2: Dataset and example augmentations ready.\n"
     ]
    }
   ],
   "source": [
    "class OneSecClipsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Assumes each .wav file in root_dir is ~1 second at 16kHz (16000 samples).\n",
    "    If sample_rate != 16000, we resample to 16k.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, sample_rate=16000):\n",
    "        super().__init__()\n",
    "        self.filepaths = glob.glob(os.path.join(root_dir, '**', '*.wav'), recursive=True)\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav_path = self.filepaths[idx]\n",
    "        waveform, sr = torchaudio.load(wav_path)\n",
    "\n",
    "        # Convert to mono if multi-channel\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        # Resample if needed\n",
    "        if sr != self.sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.sample_rate)\n",
    "            waveform  = resampler(waveform)\n",
    "\n",
    "        # Ensure exactly 16000 samples (pad or crop)\n",
    "        if waveform.shape[1] > AUDIO_LEN:\n",
    "            waveform = waveform[:, :AUDIO_LEN]\n",
    "        elif waveform.shape[1] < AUDIO_LEN:\n",
    "            pad_len = AUDIO_LEN - waveform.shape[1]\n",
    "            waveform = F.pad(waveform, (0, pad_len))\n",
    "\n",
    "        return waveform  # shape: (1, 16000)\n",
    "\n",
    "###########################################\n",
    "# Optional Simple Augmentations (example) #\n",
    "###########################################\n",
    "def watermark_masking_augmentation(wav, p_replace_zero=0.1, p_replace_noise=0.1):\n",
    "    \"\"\"\n",
    "    Simple example of random zero or noise segments to simulate partial corruption.\n",
    "    \"\"\"\n",
    "    T = wav.shape[1]\n",
    "    window_len = int(0.1 * 16000)  # 0.1 second\n",
    "    k = 2  # do it a couple times\n",
    "    for _ in range(k):\n",
    "        start = random.randint(0, T - window_len)\n",
    "        end   = start + window_len\n",
    "        choice = random.random()\n",
    "        if choice < p_replace_zero:\n",
    "            wav[:, start:end] = 0.0\n",
    "        elif choice < p_replace_zero + p_replace_noise:\n",
    "            wav[:, start:end] = 0.1 * torch.randn_like(wav[:, start:end])\n",
    "        # else do nothing\n",
    "    return wav\n",
    "\n",
    "def robustness_augmentations(wav):\n",
    "    \"\"\"\n",
    "    Add small background noise.\n",
    "    \"\"\"\n",
    "    wav = wav + 0.005 * torch.randn_like(wav)\n",
    "    return wav\n",
    "\n",
    "print(\"\\nCHUNK #2: Dataset and example augmentations ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHUNK #3: Generator with residual blocks, LSTM, message embedding defined.\n"
     ]
    }
   ],
   "source": [
    "def make_conv1d(in_ch, out_ch, kernel_size=3, stride=1, padding=1):\n",
    "    return nn.Conv1d(in_ch, out_ch, kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.downsample = (stride != 1 or in_ch != out_ch)\n",
    "        self.conv1 = make_conv1d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1)\n",
    "        self.conv2 = make_conv1d(out_ch, out_ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.elu   = nn.ELU()\n",
    "        \n",
    "        if self.downsample:\n",
    "            self.skip_conv = make_conv1d(in_ch, out_ch, kernel_size=1, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.elu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.skip_conv(residual)\n",
    "        out = self.elu(out + residual)\n",
    "        return out\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels=1, \n",
    "                 base_channels=CHANNELS,\n",
    "                 hidden_dim=HIDDEN_DIM, \n",
    "                 message_bits=NUM_BITS,\n",
    "                 output_channels=OUTPUT_CH, \n",
    "                 strides=STRIDES):\n",
    "        super().__init__()\n",
    "        self.message_bits = message_bits\n",
    "        self.hidden_dim   = hidden_dim\n",
    "        \n",
    "        # Embedding for integer messages\n",
    "        self.E = nn.Embedding(num_embeddings=(2**message_bits), embedding_dim=hidden_dim)\n",
    "\n",
    "        # --------- Encoder --------- #\n",
    "        self.init_conv = nn.Conv1d(in_channels, base_channels, kernel_size=7, stride=1, padding=3)\n",
    "\n",
    "        enc_blocks = []\n",
    "        ch = base_channels\n",
    "        for st in strides:\n",
    "            out_ch = ch * 2\n",
    "            enc_blocks.append(ResidualBlock(ch, out_ch, stride=st))\n",
    "            ch = out_ch\n",
    "        self.encoder_blocks = nn.Sequential(*enc_blocks)\n",
    "\n",
    "        # Project encoder output to hidden_dim\n",
    "        self.proj = nn.Linear(ch, hidden_dim)  # ch after all enc blocks\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=2,\n",
    "                            batch_first=True, bidirectional=False)\n",
    "\n",
    "        self.final_conv_enc = nn.Conv1d(hidden_dim, output_channels, kernel_size=7, stride=1, padding=3)\n",
    "\n",
    "        # --------- Decoder --------- #\n",
    "        dec_blocks = []\n",
    "        rev_strides = list(reversed(strides))\n",
    "        in_ch = output_channels  # start with 128\n",
    "        for st in rev_strides:\n",
    "            out_ch = in_ch // 2\n",
    "            dec_blocks.append(\n",
    "                nn.ConvTranspose1d(in_ch, out_ch, kernel_size=2*st, stride=st,\n",
    "                                   padding=(st//2), output_padding=0)\n",
    "            )\n",
    "            dec_blocks.append(ResidualBlock(out_ch, out_ch, stride=1))\n",
    "            in_ch = out_ch\n",
    "        self.decoder_blocks = nn.Sequential(*dec_blocks)\n",
    "\n",
    "        self.final_conv_dec = nn.Conv1d(in_ch, 1, kernel_size=7, stride=1, padding=3)\n",
    "\n",
    "    def forward(self, s, message=None):\n",
    "        B, _, T = s.shape\n",
    "        x = self.init_conv(s)\n",
    "        x = self.encoder_blocks(x)\n",
    "        x_t = x.transpose(1, 2)  # shape (B, T_after, ch)\n",
    "\n",
    "        x_t = self.proj(x_t)  # (B, T_after, hidden_dim)\n",
    "\n",
    "        if message is not None:\n",
    "            e = self.E(message)  # (B, hidden_dim)\n",
    "            T_after = x_t.shape[1]\n",
    "            e_expanded = e.unsqueeze(1).expand(-1, T_after, -1)\n",
    "            x_t = x_t + e_expanded\n",
    "\n",
    "        lstm_out, _ = self.lstm(x_t)\n",
    "        lstm_out_t = lstm_out.transpose(1, 2)\n",
    "        latent = self.final_conv_enc(lstm_out_t)\n",
    "\n",
    "        x_dec = latent\n",
    "        x_dec = self.decoder_blocks(x_dec)\n",
    "        delta = self.final_conv_dec(x_dec)\n",
    "\n",
    "        # Adjust final length if needed\n",
    "        if delta.shape[-1] != T:\n",
    "            min_len = min(delta.shape[-1], T)\n",
    "            delta = delta[:, :, :min_len]\n",
    "            if min_len < T:\n",
    "                pad_amt = T - min_len\n",
    "                delta = F.pad(delta, (0, pad_amt))\n",
    "\n",
    "        return delta\n",
    "\n",
    "print(\"\\nCHUNK #3: Generator with residual blocks, LSTM, message embedding defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHUNK #4: Detector network defined.\n"
     ]
    }
   ],
   "source": [
    "class Detector(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels=1, \n",
    "                 base_channels=CHANNELS,\n",
    "                 hidden_dim=HIDDEN_DIM,\n",
    "                 message_bits=NUM_BITS,\n",
    "                 strides=STRIDES):\n",
    "        super().__init__()\n",
    "        self.message_bits = message_bits\n",
    "\n",
    "        self.init_conv = nn.Conv1d(in_channels, base_channels, kernel_size=7, stride=1, padding=3)\n",
    "\n",
    "        enc_blocks = []\n",
    "        ch = base_channels\n",
    "        for st in strides:\n",
    "            out_ch = ch * 2\n",
    "            enc_blocks.append(ResidualBlock(ch, out_ch, stride=st))\n",
    "            ch = out_ch\n",
    "        self.encoder_blocks = nn.Sequential(*enc_blocks)\n",
    "\n",
    "        dec_blocks = []\n",
    "        rev_strides = list(reversed(strides))\n",
    "        in_ch = ch\n",
    "        for st in rev_strides:\n",
    "            out_ch = in_ch // 2\n",
    "            dec_blocks.append(\n",
    "                nn.ConvTranspose1d(in_ch, out_ch, kernel_size=2*st, stride=st,\n",
    "                                   padding=(st//2), output_padding=0)\n",
    "            )\n",
    "            dec_blocks.append(ResidualBlock(out_ch, out_ch, stride=1))\n",
    "            in_ch = out_ch\n",
    "        self.upsample_blocks = nn.Sequential(*dec_blocks)\n",
    "\n",
    "        # final: 1 channel for detection + message_bits channels for bit decoding\n",
    "        self.final_conv = nn.Conv1d(base_channels, 1 + message_bits, kernel_size=7, stride=1, padding=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        original_length = x.shape[-1]\n",
    "\n",
    "        # Encoder\n",
    "        x = self.init_conv(x)\n",
    "        x = self.encoder_blocks(x)\n",
    "\n",
    "        # Upsample\n",
    "        x = self.upsample_blocks(x)\n",
    "        out = self.final_conv(x)\n",
    "\n",
    "        # Adjust length if needed\n",
    "        if out.shape[-1] > original_length:\n",
    "            out = out[:, :, :original_length]\n",
    "        elif out.shape[-1] < original_length:\n",
    "            pad_amt = original_length - out.shape[-1]\n",
    "            out = F.pad(out, (0, pad_amt))\n",
    "            \n",
    "        return out  # shape (B, 1+bits, T)\n",
    "\n",
    "print(\"\\nCHUNK #4: Detector network defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHUNK #5: Minimal bit helpers defined (no custom spectral or adversarial losses).\n"
     ]
    }
   ],
   "source": [
    "def generate_random_messages(batch_size, num_bits=NUM_BITS):\n",
    "    \"\"\"\n",
    "    Generates random integers in [0, 2^num_bits - 1].\n",
    "    \"\"\"\n",
    "    max_val = 2 ** num_bits\n",
    "    return torch.randint(0, max_val, (batch_size,))\n",
    "\n",
    "def int_to_bit_tensor(msgs_int, num_bits=NUM_BITS):\n",
    "    \"\"\"\n",
    "    Convert integer messages => bit vectors of shape (B, num_bits), each in {0,1}.\n",
    "    bits[0] = LSB, bits[num_bits-1] = MSB by default here.\n",
    "    \"\"\"\n",
    "    B = msgs_int.shape[0]\n",
    "    bit_list = []\n",
    "    for bit_idx in range(num_bits):\n",
    "        bit_i = ((msgs_int >> bit_idx) & 1).float()  # shape (B,)\n",
    "        bit_list.append(bit_i)\n",
    "    # Stack along dimension=1 => shape (B,num_bits)\n",
    "    bits = torch.stack(bit_list, dim=1)\n",
    "    return bits\n",
    "\n",
    "print(\"\\nCHUNK #5: Minimal bit helpers defined (no custom spectral or adversarial losses).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHUNK #6: Updated training code with L1 + BCE complete.\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(\n",
    "    generator,\n",
    "    detector,\n",
    "    train_loader,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    total_epochs,\n",
    "    device,\n",
    "    num_bits=NUM_BITS\n",
    "):\n",
    "    generator.train()\n",
    "    detector.train()\n",
    "    \n",
    "    l1_loss_fn = nn.L1Loss().to(device)\n",
    "    bce_loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "    \n",
    "    total_steps = len(train_loader)\n",
    "    sum_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=total_steps, desc=f\"Epoch [{epoch}/{total_epochs}]\")\n",
    "    \n",
    "    for i, s in pbar:\n",
    "        s = s.to(device)  # (B,1,T)\n",
    "        B = s.shape[0]\n",
    "        \n",
    "        # (Optional) augment: e.g. we might do nothing on original or do partial\n",
    "        # s = watermark_masking_augmentation(s)  # typically you do this on watermarked audio, but you can adapt\n",
    "\n",
    "        # 1) Generate random messages (int)\n",
    "        msgs_int = generate_random_messages(B, num_bits=num_bits).to(device)\n",
    "        \n",
    "        # 2) Generator forward => get delta, then s_w\n",
    "        delta = generator(s, msgs_int)  # (B,1,T)\n",
    "        s_w = s + delta  # watermarked\n",
    "        \n",
    "        # (Optional) augment the watermarked signal (simulate channel noise, etc.)\n",
    "        # for b_idx in range(B):\n",
    "        #     s_w[b_idx] = robustness_augmentations(s_w[b_idx])\n",
    "        \n",
    "        # 3) Detector forward => shape (B, 1+num_bits, T)\n",
    "        det_out = detector(s_w)\n",
    "        \n",
    "        # *** Distortion Loss (L1) ***\n",
    "        loss_dist = l1_loss_fn(s_w, s)\n",
    "\n",
    "        # *** Detection Loss (BCE) ***\n",
    "        # We assume everything in the batch is watermarked => label=1\n",
    "        # det_out[:,0,:] => detection channel => (B, T)\n",
    "        detection_map = det_out[:, 0, :]        # (B, T)\n",
    "        detection_avg = detection_map.mean(dim=1)  # (B,)\n",
    "        label_det = torch.ones(B, device=device)  # all 1\n",
    "        loss_det = bce_loss_fn(detection_avg, label_det)\n",
    "\n",
    "        # *** Bit Decoding Loss (BCE) ***\n",
    "        # det_out[:,1:,:] => (B, num_bits, T)\n",
    "        bit_map = det_out[:, 1:, :]  # (B, num_bits, T)\n",
    "        bit_avg = bit_map.mean(dim=2)  # average over time => (B, num_bits)\n",
    "        bit_labels = int_to_bit_tensor(msgs_int, num_bits=num_bits).to(device)  # (B, num_bits)\n",
    "        loss_bits = bce_loss_fn(bit_avg, bit_labels)\n",
    "\n",
    "        # Weighted sum\n",
    "        lambda_l1   = 1.0\n",
    "        lambda_det  = 1.0\n",
    "        lambda_bits = 1.0\n",
    "        \n",
    "        loss = lambda_l1*loss_dist + lambda_det*loss_det + lambda_bits*loss_bits\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "        pbar.set_postfix({\n",
    "            \"dist\": f\"{loss_dist.item():.3f}\",\n",
    "            \"det\": f\"{loss_det.item():.3f}\",\n",
    "            \"bits\": f\"{loss_bits.item():.3f}\",\n",
    "            \"total\": f\"{loss.item():.3f}\"\n",
    "        })\n",
    "    \n",
    "    avg_loss = sum_loss / (total_steps if total_steps > 0 else 1)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def validate_one_epoch(\n",
    "    generator,\n",
    "    detector,\n",
    "    val_loader,\n",
    "    device,\n",
    "    num_bits=NUM_BITS\n",
    "):\n",
    "    generator.eval()\n",
    "    detector.eval()\n",
    "\n",
    "    l1_loss_fn = nn.L1Loss().to(device)\n",
    "    bce_loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "    sum_loss = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for s in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "            s = s.to(device)\n",
    "            B = s.shape[0]\n",
    "\n",
    "            msgs_int = generate_random_messages(B, num_bits=num_bits).to(device)\n",
    "\n",
    "            delta = generator(s, msgs_int)\n",
    "            s_w   = s + delta\n",
    "            det_out = detector(s_w)\n",
    "\n",
    "            # Distortion\n",
    "            loss_dist = l1_loss_fn(s_w, s)\n",
    "\n",
    "            # Detection (all are watermarked => label=1)\n",
    "            detection_map = det_out[:, 0, :]\n",
    "            detection_avg = detection_map.mean(dim=1)\n",
    "            label_det = torch.ones(B, device=device)\n",
    "            loss_det = bce_loss_fn(detection_avg, label_det)\n",
    "\n",
    "            # Bit decoding\n",
    "            bit_map = det_out[:, 1:, :]\n",
    "            bit_avg = bit_map.mean(dim=2)\n",
    "            bit_labels = int_to_bit_tensor(msgs_int, num_bits=num_bits).to(device)\n",
    "            loss_bits = bce_loss_fn(bit_avg, bit_labels)\n",
    "\n",
    "            loss = loss_dist + loss_det + loss_bits\n",
    "            sum_loss += loss.item()\n",
    "            steps += 1\n",
    "\n",
    "    return sum_loss / max(1, steps)\n",
    "\n",
    "def train_model(\n",
    "    generator,\n",
    "    detector,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    num_epochs=10,\n",
    "    lr=1e-3,\n",
    "    num_bits=NUM_BITS\n",
    "):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        list(generator.parameters()) + list(detector.parameters()),\n",
    "        lr=lr\n",
    "    )\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        train_loss = train_one_epoch(generator, detector, train_loader, optimizer, epoch, num_epochs, device, num_bits)\n",
    "        val_loss   = validate_one_epoch(generator, detector, val_loader, device, num_bits)\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}]  TRAIN Loss: {train_loss:.4f}  |  VAL Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"\\nCHUNK #6: Updated training code with L1 + BCE complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHUNK #7: Simple inference utilities (detection, decoding) complete.\n"
     ]
    }
   ],
   "source": [
    "def detect_watermark(detector, audio, threshold=0.5):\n",
    "    \"\"\"\n",
    "    audio: (B,1,T)\n",
    "    Returns True/False if average detection probability > threshold\n",
    "    \"\"\"\n",
    "    detector.eval()\n",
    "    with torch.no_grad():\n",
    "        out = detector(audio)  # (B, 1+bits, T)\n",
    "        det_prob = out[:, 0, :]  # detection channel => shape (B, T)\n",
    "        avg_prob = det_prob.mean(dim=1)  # (B,)\n",
    "        return (torch.sigmoid(avg_prob) > threshold).float()\n",
    "\n",
    "def decode_message(detector, audio, num_bits=NUM_BITS):\n",
    "    \"\"\"\n",
    "    audio: (B,1,T)\n",
    "    Return integer messages predicted by the detector.\n",
    "    We average bit channels over time, threshold at 0.5, convert bits => int.\n",
    "    \"\"\"\n",
    "    detector.eval()\n",
    "    with torch.no_grad():\n",
    "        out = detector(audio)  # (B, 1+bits, T)\n",
    "        bit_map = out[:, 1:, :]  # (B, num_bits, T)\n",
    "        bit_avg = bit_map.mean(dim=2)  # (B, num_bits)\n",
    "        bit_prob = torch.sigmoid(bit_avg)  # convert logits => prob\n",
    "        bit_pred = (bit_prob > 0.5).int()\n",
    "\n",
    "        # convert bits => integer\n",
    "        B, b = bit_pred.shape\n",
    "        msg_int = torch.zeros(B, dtype=torch.long, device=bit_pred.device)\n",
    "        for i in range(b):\n",
    "            msg_int |= (bit_pred[:, i] << i)\n",
    "        return msg_int  # shape (B,)\n",
    "\n",
    "print(\"\\nCHUNK #7: Simple inference utilities (detection, decoding) complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m train_ds, val_ds, test_ds \u001b[38;5;241m=\u001b[39m random_split(full_dataset, [n_train, n_val, n_test])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 3) Instantiate models\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m detector  \u001b[38;5;241m=\u001b[39m Detector()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 4) Train\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Load dataset\n",
    "    data_root = \"data/100_all\"  # Change this to your data folder\n",
    "    full_dataset = OneSecClipsDataset(root_dir=data_root, sample_rate=16000)\n",
    "\n",
    "    # 2) Split\n",
    "    n = len(full_dataset)\n",
    "    n_train = int(0.8 * n)\n",
    "    n_val   = int(0.1 * n)\n",
    "    n_test  = n - n_train - n_val\n",
    "    train_ds, val_ds, test_ds = random_split(full_dataset, [n_train, n_val, n_test])\n",
    "\n",
    "    # 3) Instantiate models\n",
    "    generator = Generator().to(device)\n",
    "    detector  = Detector().to(device)\n",
    "\n",
    "    # 4) Train\n",
    "    train_model(generator, detector, train_ds, val_ds, num_epochs=10, lr=LR, num_bits=NUM_BITS)\n",
    "\n",
    "    # 5) Save\n",
    "    torch.save(generator.state_dict(), \"generator.pth\")\n",
    "    torch.save(detector.state_dict(), \"detector.pth\")\n",
    "\n",
    "    # 6) Example: quick check on test sample\n",
    "    test_loader = DataLoader(test_ds, batch_size=1, shuffle=True)\n",
    "    for audio in test_loader:\n",
    "        audio = audio.to(device)\n",
    "        # embed random message\n",
    "        msg_int = generate_random_messages(1, num_bits=NUM_BITS).to(device)\n",
    "        delta = generator(audio, msg_int)\n",
    "        s_w   = audio + delta\n",
    "        # detect\n",
    "        detection_label = detect_watermark(detector, s_w, threshold=0.5)\n",
    "        pred_msg        = decode_message(detector, s_w, num_bits=NUM_BITS)\n",
    "        print(f\"True msg: {msg_int.item()},  Predicted msg: {pred_msg.item()},  Detected? {detection_label.item()>0.5}\")\n",
    "        break  # just do 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
